import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.pipeline import make_pipeline
import warnings

# # Ignore FutureWarnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# # Load dataset
houseprice_df = pd.read_excel('HousePrice_Dataset.xlsx')
houseprice_df.head()

# # Checking input data shape & info
df = houseprice_df.copy()
df=df.dropna()

df=df.drop(['total_rooms','total_bedrooms','population'], axis=1)

# Calculate the upper and lower limits
Q1 = df['median_house_value'].quantile(0.25)
Q3 = df['median_house_value'].quantile(0.75)
IQR = Q3 - Q1

# Set the threshold for outliers
lower_threshold = Q1 - 1.5 * IQR
upper_threshold = Q3 + 1.5 * IQR

# Identify outlier rows using boolean masks
outliers_lower = df['median_house_value'] < lower_threshold
outliers_upper = df['median_house_value'] > upper_threshold

# Display the number of outliers
print(f"Number of lower outliers: {outliers_lower.sum()}")
print(f"Number of upper outliers: {outliers_upper.sum()}")

# Remove the outliers
df = df[~(outliers_lower | outliers_upper)].copy()


# Convert categorical variable 'ocean_proximity' into dummy/indicator variables
df = pd.get_dummies(df, columns=['ocean_proximity'])
df.head()

# # Separate features (X) and target variable (y)
X = df.drop('median_house_value', axis=1)
y = df['median_house_value']

# # Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Create a pipeline with StandardScaler and PolynomialFeatures
# pipeline = make_pipeline(StandardScaler(), PolynomialFeatures(degree=2, include_bias=False))

# # Fit and transform the training data
# X_train_poly = pipeline.fit_transform(X_train)

# # Transform the testing data
# X_test_poly = pipeline.transform(X_test)

# Build a multi-layer neural network model
model = Sequential()
model.add(Dense(128, input_dim=X_train_poly.shape[1], activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='linear'))

# Compile the model
model.compile(optimizer='ADAM', loss='mean_squared_error')

# Train the model
model.fit(X_train_poly, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)

# Make predictions on the test set
predictions = model.predict(X_test_poly).flatten()

# Evaluate the model
mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

# Make predictions on the test set
predictions = model.predict(X_test_poly).flatten()

# Plotting actual vs predicted values with different colors
plt.figure(figsize=(10, 6))
plt.scatter(y_test, predictions, c='blue', label='Actual vs Predicted', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red', label='Perfect Prediction Line')
plt.title('Actual vs Predicted House Prices')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.legend()
plt.show()
