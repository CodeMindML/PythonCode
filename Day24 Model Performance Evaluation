#Evaluation Metric for CLassification models

# Importing necessary functions from scikit-learn metrics module
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Sample actual and predicted labels for a binary classification task
actual_labels = [1, 0, 0, 1, 0, 1, 0, 1, 0, 0]
predicted_labels = [1, 0, 1, 0, 0, 1, 0, 1, 1, 0]

# Computing classification metrics

# Accuracy: Ratio of correctly predicted observations to the total observations.
accuracy = accuracy_score(actual_labels, predicted_labels)

# Precision: Ratio of true positives to the sum of true positives and false positives.
precision = precision_score(actual_labels, predicted_labels)

# Recall: Ratio of true positives to the sum of true positives and false negatives.
recall = recall_score(actual_labels, predicted_labels)

# F1-Score: Harmonic mean of precision and recall, balances false positives and false negatives.
f1 = f1_score(actual_labels, predicted_labels)

# Confusion Matrix: Table showing true positives, true negatives, false positives, and false negatives.
conf_matrix = confusion_matrix(actual_labels, predicted_labels)

# Displaying the computed metrics
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-Score:", f1)
print("Confusion Matrix:\n", conf_matrix)

#Evaluation Metric for Regression
# Importing necessary functions from scikit-learn metrics module
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error

# Sample actual and predicted values for a regression task
actual_values = [10, 25, 30, 45, 50]
predicted_values = [12, 24, 28, 44, 51]

# Computing regression metrics

# Mean Absolute Error (MAE): Average absolute difference between actual and predicted values.
mae = mean_absolute_error(actual_values, predicted_values)

# Mean Squared Error (MSE): Average of the squared differences between actual and predicted values.
mse = mean_squared_error(actual_values, predicted_values)

# R-squared (R2): Proportion of the variance in the dependent variable that is predictable from the independent variable.
r2 = r2_score(actual_values, predicted_values)

# Median Absolute Error (MedAE): Median of the absolute differences between actual and predicted values.
medae = median_absolute_error(actual_values, predicted_values)

# Displaying the computed regression metrics
print("Mean Absolute Error:", mae)
print("Mean Squared Error:", mse)
print("R-squared:", r2)
print("Median Absolute Error:", medae)

